# -*- coding: utf-8 -*-
"""stdsparks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MPhRsS9ca8xYGpFXtoj0_91g6uv1IEQ8

DATA SCIENCE AND BUSINESS ANALYTICS TASK

**Prediction using Supervised ML**
Predict the percentage of an student based on the no. of study hours.
#GRIP task 1
#GRIP AUGUST BATCH21
NAME- VARTIKA JAISWAL
"""

import sys
print('Python: {}'.format(sys.version))
# scipy
import scipy
print('scipy: {}'.format(scipy.__version__))
# numpy
import numpy
print('numpy: {}'.format(numpy.__version__))
# matplotlib
import matplotlib
print('matplotlib: {}'.format(matplotlib.__version__))
# pandas
import pandas
print('pandas: {}'.format(pandas.__version__))
# scikit-learn
import sklearn
print('sklearn: {}'.format(sklearn.__version__))

# Commented out IPython magic to ensure Python compatibility.
import pandas
#from pandas.tools.plotting import scatter_matrix
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn.metrics import classification_report
from sklearn.linear_model import LinearRegression

# Load dataset
names = ['Hours']		#column names 
# Reading data from remote link

url = "http://bit.ly/w-data"
dataset = pandas.read_csv(url)
# Dimensions of dataset
#shape
print(dataset.shape) 
#dataset = numpy.array([2.4, 6.2, 1.8, 9.0]).reshape(-1, 1)
print(dataset.head(10))

dataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)
plt.show()

dataset.plot(x='Hours', y='Scores', style='o')  
plt.title('Hours vs Percentage')  
plt.xlabel('Hours Studied')  
plt.ylabel('Percentage Score')  
plt.show()

# Plotting the regression line
line = regressor.coef_*X+regressor.intercept_

# Plotting for the test data
plt.scatter(X, Y)
plt.plot(X, line,'Y')
plt.show()

X = dataset.iloc[:, :-1].values  
Y = dataset.iloc[:, 1].values

from sklearn.model_selection import train_test_split  
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, 
                            test_size=0.2, random_state=0)

#prediction of logistic regression#
from sklearn.linear_model import LinearRegression  
regressor = LinearRegression()  
#regressor.fit(x.reshape(-1, 1), y)
regressor.fit(X_train, Y_train)

#best value of intercept
print(regressor.intercept_)

#for retrieving the slope
print(regressor.coef_)

#predicting the dataset and comparing with actual value
y_pred = regressor.predict(X_test)
df = pandas.DataFrame({'Actual': Y_test, 'Predicted': y_pred})
df

#predicted 9.25 hours
our_pred = regressor.predict([[9.25]])
print(our_pred)

from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error:', numpy.sqrt(metrics.mean_squared_error(Y_test, y_pred)))

from sklearn.tree import DecisionTreeClassifier
classifier = DecisionTreeClassifier()
classifier.fit(X_train, Y_train)

y_pred = classifier.predict(X_test)

from sklearn import metrics
print('Mean Absolute Error:', metrics.mean_absolute_error(Y_test, y_pred))
print('Mean Squared Error:', metrics.mean_squared_error(Y_test, y_pred))
print('Root Mean Squared Error:', numpy.sqrt(metrics.mean_squared_error(Y_test, y_pred)))

#we see that rms value for linear regression is less than decision tree so LR is a better classifier for prediction